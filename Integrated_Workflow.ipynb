{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.utils import simple_preprocess, lemmatize\n",
    "import gensim.corpora as corpora\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from topic_modeling import get_new_topic_probs, get_topic_probs\n",
    "import pronouncing\n",
    "import copy\n",
    "import textstat\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "import string\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import log_loss\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "import random\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from AutoCluster import AutoKMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Preprocessing\n",
    "\n",
    "1. Import datasets\n",
    "2. Split training data into train and val\n",
    "3. Create dummy variable for each author from training data\n",
    "4. Split newly created dummies into train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "X_train, X_val, y_train, y_val = train_test_split(df.drop('author', axis = 1),encoder.fit_transform(df.author), random_state=0, test_size = .2)\n",
    "\n",
    "\n",
    "author_df=pd.DataFrame(0,columns=(['Poe','Lovecraft','Shelley']),index=train.index)\n",
    "df.Poe = df.author.apply(lambda x: 1 if x=='EAP' else 0)\n",
    "df.Shelley = df.author.apply(lambda x: 1 if x=='MWS' else 0)\n",
    "df.Lovecraft = df.author.apply(lambda x: 1 if x=='HPL' else 0)\n",
    "\n",
    "\n",
    "Poey_train, Poey_val = train_test_split(author_df.Poe, random_state=0, test_size = .2)\n",
    "Lovecrafty_train, Lovecrafty_val = train_test_split(author_df.Lovecraft, random_state=0, test_size = .2)\n",
    "Shelleyy_train, Shelleyy_val = train_test_split(author_df.Shelley, random_state=0, test_size = .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost with LSTM neural network as base estimator\n",
    "\n",
    "1. Tokenize texts\n",
    "2. Instantiate Adaboost with LSTM base estimator\n",
    "3. Get multi-class and multi-label predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize texts\n",
    "tk.fit_on_texts(X_train.text)\n",
    "train_post = tk.texts_to_sequences(X_train.text)\n",
    "X_train_post = pad_sequences(train_post,255,truncating='post')\n",
    "val_post = tk.texts_to_sequences(X_val.text)\n",
    "X_val_post = pad_sequences(val_post,255,truncating='post')\n",
    "test_post = tk.texts_to_sequences(test_df.text)\n",
    "X_test_post = pad_sequences(test_post,255,truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define neural network architecture within a function, apply sklearn wrapper and instantiate adaboost\n",
    "np.random.seed(0)\n",
    "def lstm(max_sequence_len = 255):\n",
    "    num_words = 5000\n",
    "    embed_vec_len = 32\n",
    "    lstm_nn = models.Sequential()\n",
    "    lstm_nn.add(layers.Embedding(num_words, embed_vec_len, input_length=max_sequence_len))\n",
    "    lstm_nn.add(layers.SpatialDropout1D(0.2))\n",
    "    lstm_nn.add(layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "    lstm_nn.add(layers.Dense(2, activation='sigmoid'))\n",
    "    lstm_nn.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['categorical_accuracy'])\n",
    "    return lstm_nn\n",
    "model = KerasClassifier(build_fn=lstm, epochs=1, batch_size=256, verbose=2)\n",
    "ada = AdaBoostClassifier(base_estimator=model,n_estimators=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiclass adaboost\n",
    "ada.fit(X_train_post,y_train)\n",
    "ada_overall_train = ada.predict(X_train_post)\n",
    "ada_overall_val = ada.predict(X_val_post)\n",
    "ada_overall_test = ada.predict(X_test_post)\n",
    "\n",
    "#multilabel adaboost\n",
    "ada.fit(X_train_post,Poey_train)\n",
    "ada_poe_train = ada.predict(X_train_post)\n",
    "ada_poe_val = ada.predict(X_val_post)\n",
    "ada_poe_test = ada.predict(X_test_post)\n",
    "ada.fit(X_train_post,Lovecrafty_train)\n",
    "ada_lovecraft_train = ada.predict(X_train_post)\n",
    "ada_lovecraft_val = ada.predict(X_val_post)\n",
    "ada_lovecraft_test = ada.predict(X_test_post)\n",
    "ada.fit(X_train_post,Shelleyy_train)\n",
    "ada_shelley_train = ada.predict(X_train_post)\n",
    "ada_shelley_val = ada.predict(X_val_post)\n",
    "ada_shelley_test = ada.predict(X_test_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tfidf vectorization\n",
    "\n",
    "1. Vectorize\n",
    "2. Predict author with naive bayes\n",
    "3. Predict author with svm\n",
    "4. Cluster vectors with KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english',max_features=12000)\n",
    "nb = MultinomialNB()\n",
    "\n",
    "svm = SVC(kernel='linear')\n",
    "encoder = LabelEncoder()\n",
    "#tokenize\n",
    "t_X_train = tfidf.fit_transform(X_train.text)\n",
    "t_X_val = tfidf.fit_transform(X_val.text)\n",
    "t_X_test = tfidf.fit_transform(test_df.text)\n",
    "\n",
    "#overall nb\n",
    "nb.fit(t_X_train,y_train)\n",
    "nb_train = nb.predict(t_X_train)\n",
    "nb_val = nb.predict(t_X_val)\n",
    "nb_test = nb.predict(t_X_test)\n",
    "\n",
    "#binary nb\n",
    "nb.fit(t_X_train,Poey_train)\n",
    "nb_poe_train = nb.predict(t_X_train)\n",
    "nb_poe_val = nb.predict(t_X_val)\n",
    "nb_poe_test = nb.predict(t_X_test)\n",
    "\n",
    "nb.fit(t_X_train,Lovecrafty_train)\n",
    "nb_lovecraft_train = nb.predict(lt_X_train)\n",
    "nb_lovecraft_val = nb.predict(lt_X_val)\n",
    "nb_lovecraft_test = nb.predict(t_X_test)\n",
    "\n",
    "nb.fit(t_X_train,Shelleyy_train)\n",
    "nb_shelley_train = nb.predict(t_X_train)\n",
    "nb_shelley_val = nb.predict(t_X_val)\n",
    "nb_shelley_test = nb.predict(t_X_test)\n",
    "\n",
    "#overall svm\n",
    "svm.fit(t_X_train,y_train)\n",
    "svm_train = svm.predict(t_X_train)\n",
    "svm_val = svm.predict(t_X_val)\n",
    "svm_test = svm.predict(t_X_test)\n",
    "\n",
    "#binary svm\n",
    "svm.fit(t_X_train,Poey_train)\n",
    "svm_poe_train = svm.predict(t_X_train)\n",
    "svm_poe_val = svm.predict(t_X_val)\n",
    "svm_poe_test = svm.predict(t_X_test)\n",
    "\n",
    "svm.fit(t_X_train,Lovecrafty_train)\n",
    "svm_lovecraft_train = svm.predict(t_X_train)\n",
    "svm_lovecraft_val = svm.predict(t_X_val)\n",
    "svm_lovecraft_test = svm.predict(t_X_test)\n",
    "\n",
    "svm.fit(t_X_train,Shelleyy_train)\n",
    "svm_shelley_train = svm.predict(t_X_train)\n",
    "svm_shelley_val = svm.predict(t_X_val)\n",
    "svm_shelley_test = svm.predict(t_X_test)\n",
    "\n",
    "#KMeans Clustering\n",
    "train_clusters, val_clusters, test_clusters = AutoKMeans(t_X_train,t_X_val,t_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine results into dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overall Results\n",
    "columns = ['Ada_1','Ada_2','NB_1','NB_2','SVM_1','SVM_2']\n",
    "overall_train = pd.get_dummies(pd.DataFrame(np.concatenate([ada_overall_train, nb_train,svm_train],axis=1),columns=columns).astype(str),drop_first=True)\n",
    "overall_val = pd.get_dummies(pd.DataFrame(np.concatenate([ada_overall_val,nb_val,svm_val],axis=1),columns=columns).astype(str),drop_first=True)\n",
    "overall_test = pd.get_dummies(pd.DataFrame(np.concatenate([ada_overall_test,nb_test,svm_test],axis=1),columns=columns).astype(str),drop_first=True)\n",
    "\n",
    "#Binary Results\n",
    "author_columns = ['Poe_'+i for i in columns] + ['Lovecraft_'+i for i in columns] + ['Shelley_'+i for i in columns]\n",
    "author_train = np.concatenate([ada_poe_train,nb_poe_train,svm_poe_train,ada_lovecraft_train,nb_lovecraft_train,svm_lovecraft_train,ada_shelley_train,nb_shelley_train,svm_shelley_train],axis=1)\n",
    "author_train = pd.DataFrame(author_train,columns=author_columns).astype(str)\n",
    "author_train = pd.get_dummies(author_train,drop_first=True)\n",
    "author_columns = ['Poe_'+i for i in columns] + ['Lovecraft_'+i for i in columns] + ['Shelley_'+i for i in columns]\n",
    "author_val = np.concatenate([ada_poe_val,nb_poe_val,svm_poe_val,ada_lovecraft_val,nb_lovecraft_val,svm_lovecraft_val,ada_shelley_val,nb_shelley_val,svm_shelley_val],axis=1)\n",
    "author_val = pd.DataFrame(author_val,columns=author_columns).astype(str)\n",
    "author_val = pd.get_dummies(author_val,drop_first=True)\n",
    "author_columns = ['Poe_'+i for i in columns] + ['Lovecraft_'+i for i in columns] + ['Shelley_'+i for i in columns]\n",
    "author_test = np.concatenate([ada_poe_test,nb_poe_test,svm_poe_test,ada_lovecraft_test,nb_lovecraft_test,svm_lovecraft_test,ada_shelley_test,nb_shelley_test,svm_shelley_test],axis=1)\n",
    "author_test = pd.DataFrame(author_test,columns=author_columns).astype(str)\n",
    "author_test = pd.get_dummies(author_test,drop_first=True)\n",
    "\n",
    "#Clusters \n",
    "train_clusters = pd.get_dummies(pd.DataFrame(train_clusters,columns=(['Clusters'])).astype(str),drop_first=True)\n",
    "val_clusters = pd.get_dummies(pd.DataFrame(val_clusters,columns=(['Clusters'])).astype(str),drop_first=True)\n",
    "test_clusters = pd.get_dummies(pd.DataFrame(test_clusters,columns=(['Clusters'])).astype(str),drop_first=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
