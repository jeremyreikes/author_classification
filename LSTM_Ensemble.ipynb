{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import log_loss\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess data for LSTM neural net\n",
    "def LSTM_preprocess(text,author):\n",
    "    tk = Tokenizer(lower = True,num_words=5000)\n",
    "    tk.fit_on_texts(text)\n",
    "    X_seq = tk.texts_to_sequences(text)\n",
    "    X = pad_sequences(X_seq,255)\n",
    "    target = pd.get_dummies(author)\n",
    "    return X, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate neural net\n",
    "def instantiate_LSTM(num_words = 5000, max_sequence_len=255, embed_vec_len=32):\n",
    "    lstm_nn = models.Sequential()\n",
    "    lstm_nn.add(layers.Embedding(num_words, embed_vec_len, input_length=max_sequence_len))\n",
    "    lstm_nn.add(layers.SpatialDropout1D(0.2))\n",
    "    lstm_nn.add(layers.Bidirectional(layers.LSTM(64)))\n",
    "    lstm_nn.add(layers.Dense(3, activation='softmax'))\n",
    "    lstm_nn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return lstm_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create ensemble of 20 LSTM neural nets, calculate weighted average of weights based on val loss, output agg pred\n",
    "def ensemble_LSTM(n_estimators=20)\n",
    "    val_loss =[]\n",
    "    bag_nn_preds = []\n",
    "    counter = 0\n",
    "    while counter < n_estimators:\n",
    "        print(counter+1)\n",
    "        lstm_nn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        sub = random.sample(range(len(X)),k=15000)\n",
    "        val = [i for i in range(len(X)) if i not in sub]\n",
    "        history = lstm_nn.fit(X[sub],target.iloc[sub,:],epochs=1,batch_size=256, validation_data=(X[val],target.iloc[val,:]))\n",
    "        val_loss.append(1-history.history['val_loss'][-1])\n",
    "        bag_nn_preds.append(lstm_nn.predict(X))\n",
    "        counter += 1\n",
    "    weights = np.array([i/sum(val_loss) for i in val_loss])\n",
    "    arr = np.zeros(np.array(bag_nn_preds).shape)\n",
    "    for i in range(len(weights)):\n",
    "        arr[i]=weights[i]*np.array(bag_nn_preds)[i]\n",
    "    bnp = np.mean(arr, axis=0)\n",
    "    return bnp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
