{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronouncing\n",
    "import copy\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "import gensim\n",
    "import re\n",
    "from collections import Counter\n",
    "import pronouncing\n",
    "import textstat\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "fimport numpy as np\n",
    "import random\n",
    "nlp = spacy.load('en_core_web_lg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sent in sentences:\n",
    "        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = simple_preprocess(str(sent), deacc=True)\n",
    "        yield(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics(num_topics, sentences):\n",
    "    common_dictionary = Dictionary(common_texts)\n",
    "    common_corpus = [common_dictionary.doc2bow(text) for text in common_texts]\n",
    "    lda = gensim.models.ldamodel.LdaModel(common_corpus, num_topics=num_topics)\n",
    "    data_words = list(sent_to_words(sentences))\n",
    "    curr_corpus = [common_dictionary.doc2bow(text) for text in data_words]\n",
    "    lda.update(curr_corpus)\n",
    "    vectors = []\n",
    "    for doc in other_corpus:\n",
    "        vector = lda[doc]\n",
    "        vectors.append(vector)\n",
    "    top_topics = []\n",
    "    for vector in vectors:\n",
    "        top_topic = sorted(vector, key = lambda x: x[1], reverse=True)[0]\n",
    "        top_topics.append(top_topic)\n",
    "    topic_numbers = [topic[0] if (abs(topic[1] - (1/num_topics)) >= .01) else -1 for topic in top_topics]\n",
    "    return topic_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_jeremy_features(row):\n",
    "    text = row.text\n",
    "    doc = nlp(text)\n",
    "    lemmas = list()\n",
    "    entities = list()\n",
    "    for token in doc:\n",
    "        if token.text == ':':\n",
    "            row['has_colon'] = 1\n",
    "        if token.text == ';':\n",
    "            row['has_semicolon'] = 1\n",
    "        if token.text == '-':\n",
    "            row['has_dash'] = 1\n",
    "        pos = token.pos_\n",
    "        row[pos] += 1\n",
    "        if token.is_stop or not token.is_alpha:\n",
    "            continue\n",
    "        lemma = token.lemma_.strip().lower()\n",
    "        if lemma:\n",
    "            lemmas.append(lemma)\n",
    "    for ent in doc.ents:\n",
    "        entities.append(ent.text)\n",
    "    lemmas = ' '.join(lemmas)\n",
    "    blob = TextBlob(text)\n",
    "    row['subjectivity'] = blob.sentiment.subjectivity\n",
    "    row['polarity'] = blob.sentiment.polarity\n",
    "    row['starts_conj'] = int(doc[0].pos_ == 'CONJ')\n",
    "    row['ends_prep'] = int(doc[0].pos_ == 'PREP')\n",
    "    row['entities'] = entities\n",
    "    row['lemmas'] = lemmas\n",
    "    row['raw_text_length'] = len(text)\n",
    "    row['num_words'] = len(doc)\n",
    "    row['avg_word_len'] = row.raw_text_length / row.num_words\n",
    "    row['vector_avg'] = np.mean(nlp(lemmas).vector)\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19578"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.apply(lambda x: add_features(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhyme_frequency(text):\n",
    "    words = list(set([i.lower() for i in text.split(' ')]))\n",
    "    num_words = len(words)\n",
    "    num_rhymes = 0\n",
    "    for i in words:\n",
    "        other = copy.copy(words)\n",
    "        other.remove(i)\n",
    "        rhymes = pronouncing.rhymes(i)\n",
    "        matches = set(other).intersection(set(rhymes))\n",
    "        num_rhymes += len(matches)/2\n",
    "    return num_rhymes/num_words\n",
    "\n",
    "def add_remy_features(df):\n",
    "    text = df.text.to_list()\n",
    "    nopunct_text = []\n",
    "    for i in text:\n",
    "        np = re.sub(r'[^\\w\\s]','',i)\n",
    "        nopunct_text.append(np)\n",
    "    df['NoPunct'] = nopunct_text\n",
    "    df['whom']=df.NoPunct.apply(lambda x: 1 if ('whom ' in x.lower()) else 0)\n",
    "    df['ing']=df.NoPunct.apply(lambda x: len([i for i in x.split(' ') if i[-3:]=='ing'])/len(x.split(' ')))\n",
    "    df['pluperfect']= df.text.apply(lambda x: 1 if ' had ' in x else 0)\n",
    "    df['rhyme_frequency'] = df.text.apply(lambda x: rhyme_frequency(x))\n",
    "    df['dale_chall'] = df.text.apply(lambda x: textstat.dale_chall_readability_score(x))\n",
    "    df['fleisch_reading_ease'] = df.text.apply(lambda x: textstat.flesch_reading_ease(x))\n",
    "    df['lexicon'] = df.text.apply(lambda x: textstat.lexicon_count(x))\n",
    "    df['word_diversity'] = df.lexicon/df.num_words\n",
    "    df.FleischReadingEase = df.fleisch_reading_ease-df.fleisch_reading_ease.min()\n",
    "    df.drop('NoPunct',axis=1,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "let_our_powers_combine = add_remy_features(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
